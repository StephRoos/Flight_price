{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4aa499",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<h1>Prédiction du prix des billets d'avion</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acaaa8c",
   "metadata": {},
   "source": [
    "L'objectif de ce projet est de prédire le prix des billets d'avion en fonction de diverses caractéristiques telles que la date de réservation, la durée du vol, le nombre d'escales, etc. Nous allons effectuer une analyse exploratoire des données (EDA) pour comprendre les relations entre les différentes variables et le prix des billets. Ensuite, nous construirons un modèle prédictif pour estimer le prix des billets en fonction des caractéristiques disponibles.\n",
    "L’objectif est d'être capable de prédire le prix des billets d’avion avec une erreur moyenne raisonnable. Plus précisément, on cherchera à obtenir une erreur absolue moyenne (MAE) inférieure à 15 €, tout en quantifiant l’incertitude associée à cette estimation à l’aide d’un intervalle de confiance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d757952",
   "metadata": {},
   "source": [
    "# Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea89285",
   "metadata": {},
   "source": [
    "- [**Les données**](#donnees)\n",
    "- [**Analyse technique**](#analyse-technique)\n",
    "  - [**Analyse univariée**](#analyse-univariee)\n",
    "  - [**Analyse multivariée**](#analyse-multivariee)\n",
    "- [**Formuler et tester des hypothèses**](#formuler-et-tester-des-hypotheses)\n",
    "- [**Preprocessing**](#preprocessing)\n",
    "- [**Modélisation**](#Modelisation)\n",
    "- [**Évaluation finale du modèle**](#evaluation-finale-du-modele)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f9750d",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd471178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_validate, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8434945",
   "metadata": {},
   "source": [
    "<a id=\"donnees\"></a>\n",
    "\n",
    "# Données et analyse fondamentale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e228a2e",
   "metadata": {},
   "source": [
    "Le dataset provient de Kaggle, et est disponible [ICI](https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction), c'est le dataset `Clean_Dataset.csv`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7668d2be",
   "metadata": {},
   "source": [
    "**Quoi** : Un total de `300.261` réservations de vol distinctes a été extrait du site et couvrent des vols programmés entre les 6 plus grandes villes d'Inde. Le dataset est une version nettoyée du dataset brut.\n",
    "\n",
    "**Quand** : Données collectées sur une période de 50 jours, du 11 février au 31 mars 2022\n",
    "\n",
    "**Où** : Les données proviennent du site web `Ease my trip`\n",
    "\n",
    "**Comment** : Scrapping avec l'outils Octoparse. Les données ont été collectées en deux parties : une pour les billets de classe économique et une autre pour les billets de classe affaires. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6944ce3e",
   "metadata": {},
   "source": [
    "\n",
    "On utilise `read_csv` de pandas pour le lire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a19de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40e9c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f42ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7e73d9f",
   "metadata": {},
   "source": [
    "**Description des colonnes :**\n",
    "\n",
    "- airline : Nom de la compagnie aérienne.\n",
    "- flight : Code du vol.\n",
    "- source_city : Ville de départ.\n",
    "- departure_time : Heure de départ (catégorisée: Morning, Afternoon, ...).\n",
    "- stops : Nombre d'escales (zero, one, two_or_more).\n",
    "- arrival_time : Heure d'arrivée (catégorisée: Morning, Afternoon, ...).\n",
    "- destination_city : Ville d'arrivée.\n",
    "- class : Classe du billet (économique ou business).\n",
    "- duration : Durée du vol (en heures).\n",
    "- days_left : Nombre de jours entre la date de réservation et la date du vol.\n",
    "- price : Prix du billet (variable cible) en Roupie indienne.\n",
    "\n",
    "Chaque ligne du dataset représente donc un vol avec ses caractéristiques et son prix associé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a007a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f77c24",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba55a52",
   "metadata": {},
   "source": [
    "<a id=\"analyse-technique\"></a>\n",
    "\n",
    "# Analyse technique du jeu de données\n",
    "\n",
    "Avant toute analyse statistique, il faut comprendre **la nature exacte des variables** que nous avons entre les mains.  \n",
    "Notre objectif ici est double :\n",
    "\n",
    "1. **Identifier le type de chaque variable**  \n",
    "   - Variable discrète ?  \n",
    "   - Variable continue ?  \n",
    "   - Date ? Texte libre ?  \n",
    "   - Fausses quantités ? (ex : durée exprimée en `String`)\n",
    "\n",
    "2. **Identifier ce que l’on peut faire avec chacune d’elles**  \n",
    "   → Est-ce qu’on peut calculer des statistiques ?  \n",
    "   → Est-ce qu’on peut compter des catégories ?  \n",
    "   → Est-ce qu’on doit transformer des colonnes avant toute analyse ?\n",
    "\n",
    "Cette étape sert à déterminer ce qui est faisable en analyse univariée et multivariée.\n",
    "\n",
    "On commence donc par lister toutes les colonnes et examiner leur contenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58cbbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aperçu des colonnes et des premiers éléments de chaque variable\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b4c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a65aa9f6",
   "metadata": {},
   "source": [
    "### Classification des variables (discrète / continue / autre)\n",
    "\n",
    "À partir du type réel (`object`, `int`, etc.) et de l'observation des valeurs, on va classifier les variables de façon statistique.\n",
    "\n",
    "- **Airline** → Discrète (catégorielle)\n",
    "- **Flight** → Discrète (catégorielle)\n",
    "- **Source_city** → Discrète (catégorielle)\n",
    "- **Departure_time** → Discrète (catégorielle ordinale)\n",
    "- **Stops** → Discrète (numérique ordinale)\n",
    "- **Arrival_time** → Discrète (catégorielle ordinale)\n",
    "- **Destination_city** → Discrète (catégorielle)\n",
    "- **Class** → Discrète (catégorielle)\n",
    "- **Duration** → Continue (numérique)\n",
    "- **Days_left** → Continue (numérique)\n",
    "- **Price** → Continue (numérique) - Variable cible\n",
    "\n",
    "On vérifie maintenant l’unicité des catégories et une statistique simple sur les variables continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_cols = [\"airline\", \"flight\", \"source_city\", \"departure_time\", \"stops\", \"arrival_time\", \"destination_city\", \"class\"]\n",
    "continues_cols = [\"duration\", \"days_left\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1fcedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comptage rapide des catégories pour les variables discrètes\n",
    "for col in discrete_cols:\n",
    "    print(f\"\\n--- {col} ---\")\n",
    "    print(original_df[col].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f50f03",
   "metadata": {},
   "source": [
    "<a id=\"analyse-univariee\"></a>\n",
    "\n",
    "## Analyse Univariée\n",
    "\n",
    "Maintenant que les variables ont été classées, on commence l’analyse statistique variable par variable.\n",
    "\n",
    "L’objectif est ici :\n",
    "\n",
    "- Pour les **variables discrètes** : lister les effectifs et visualiser les catégories majoritaires/minoritaires.  \n",
    "- Pour les **variables continues** : voir la distribution, les valeurs extrêmes, les asymétries, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def univ_analysis_discrete(col_name, max_unique=20):\n",
    "    print(f\"\\n===== {col_name} =====\")\n",
    "    display(original_df[col_name].value_counts())\n",
    "    # Bar plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    if original_df[col_name].nunique() <= max_unique:\n",
    "        original_df[col_name].value_counts().plot(kind='bar')\n",
    "        plt.title(f\"Distribution of {col_name}\")\n",
    "        plt.xlabel(col_name)\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.xticks(rotation=45)\n",
    "    else:\n",
    "        original_df[col_name].value_counts().nlargest(max_unique).plot(kind='bar')\n",
    "        plt.title(f\"Top {max_unique} categories of {col_name}\")\n",
    "        plt.xlabel(col_name)\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "def univ_analysis_continuous(col_name, nbins=30):\n",
    "    print(f\"\\n===== {col_name} =====\")\n",
    "    display(original_df[col_name].describe())\n",
    "    # box plot and histogram\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    original_df.boxplot(column=col_name)\n",
    "    plt.title(f\"Box plot pour {col_name}\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    original_df[col_name].hist(bins=nbins)\n",
    "    plt.title(f\"Histograme pour {col_name}\")\n",
    "    plt.xlabel(col_name)\n",
    "    plt.ylabel(\"Fréquence\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e643f6",
   "metadata": {},
   "source": [
    "### Price\n",
    "\n",
    "On commence par la variable cible `Price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f966d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_analysis_continuous(\"price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a24778",
   "metadata": {},
   "source": [
    "- La moyenne du prix est de 20800 Roupies, mais la médiane est à 7400 Roupies, ce qui indique une distribution asymétrique avec une longue queue à droite (quelques billets très chers). C'est ce qu'on observe dans l'histogramme.\n",
    "- Les deux groupes de prix correspondent en fait aux classes économique et business."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1278e2b",
   "metadata": {},
   "source": [
    "### Airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8498f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_analysis_discrete(\"airline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007dbaaf",
   "metadata": {},
   "source": [
    "- Variable **discrète**, à forte part de marché inégale.  \n",
    "- Impact probable sur le prix → à analyser dans la partie *multivariée*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6611dbcf",
   "metadata": {},
   "source": [
    "### Source_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150f5215",
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_analysis_discrete(\"source_city\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a8a54c",
   "metadata": {},
   "source": [
    " - Peut fortement influencer le prix selon la destination → à explorer plus loin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247f91bd",
   "metadata": {},
   "source": [
    "### Departure_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab643d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_analysis_discrete(\"departure_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205b84ee",
   "metadata": {},
   "source": [
    "- Très peu de vols tardifs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd70c46d",
   "metadata": {},
   "source": [
    "### Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d67671",
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_analysis_discrete(\"stops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98631f64",
   "metadata": {},
   "source": [
    "- Variable **discrète ordinale** (zero/One/two_or_more stops). \n",
    "- À transformer en variable numérique ordonnée pour la modélisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dcf173",
   "metadata": {},
   "source": [
    "### Arrival_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d873db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_analysis_discrete(\"arrival_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5bfcad",
   "metadata": {},
   "source": [
    "- Beaucoup de vols arrivent tard le soir ou la nuit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d953eda",
   "metadata": {},
   "source": [
    "### Destination_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e73f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_analysis_discrete(\"destination_city\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba23a55",
   "metadata": {},
   "source": [
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aa991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_analysis_discrete(\"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a887f859",
   "metadata": {},
   "source": [
    "- À peu près deux fois plus de billets en classe économique qu'en classe business."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b41095",
   "metadata": {},
   "source": [
    "On poursuit avec l’analyse des **variables continues** du dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74041019",
   "metadata": {},
   "source": [
    "### Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a1051",
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_analysis_continuous(\"duration\", nbins=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b02fa",
   "metadata": {},
   "source": [
    "### Days_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_analysis_continuous(\"days_left\", nbins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63fad67",
   "metadata": {},
   "source": [
    "<a id=\"analyse-multivariee\"></a>\n",
    "\n",
    "## Analyse multivariée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bc87f8",
   "metadata": {},
   "source": [
    "On s'interesse maintenant aux relations entre les différentes variables. Notamment comment les variables influencent le prix des billets d'avion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc34a4d",
   "metadata": {},
   "source": [
    "### Relation entre la durée du vol et le prix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06322be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée des tranches (bins)\n",
    "original_df[\"duration_bin\"] = pd.cut(original_df[\"duration\"], bins=[0,5,10,20,40,60])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "...\n",
    "plt.title(\"Prix par tranche de duration\")\n",
    "plt.xlabel(\"Tranche de durée de vol\")\n",
    "plt.ylabel(\"Prix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cb5a4c",
   "metadata": {},
   "source": [
    "Ici, les prix moyens semblent varier positivement avec la durée du vol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ca1a1d",
   "metadata": {},
   "source": [
    "### Relation entre le prix et la compagnie aérienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c585eced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relation entre airline et price\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=original_df, x=\"airline\", y=\"price\")\n",
    "plt.title(\"Relation entre la compagnie aérienne et le prix\")\n",
    "plt.xlabel(\"Compagnie aérienne\")\n",
    "plt.ylabel(\"Prix (Roupies)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c269446",
   "metadata": {},
   "source": [
    "On remarque des valeurs plus élevées pour certaines compagnies aériennes, ici Vistara et Air India, ce qui suggère que la compagnie propose un service premium par exemple.\n",
    "\n",
    "\n",
    "La compagnie aérienne **semble** avoir un impact significatif sur le prix des billets d'avion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f949637c",
   "metadata": {},
   "source": [
    "### Relation entre le nombre d'escales et le prix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c931fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relation entre stops et price\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=original_df, x=\"stops\", y=\"price\")\n",
    "plt.title(\"Relation entre le nombre d'escales et le prix\")\n",
    "plt.xlabel(\"Nombre d'escales\")\n",
    "plt.ylabel(\"Prix (Roupies)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87047c3",
   "metadata": {},
   "source": [
    "En moyenne, le prix est plus élevé pour les vols avec au moins une escale. Cependant, il y a une grande variabilité des prix pour chaque catégorie d'escales, indiquant que d'autres facteurs influencent également le prix des billets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7645ac8f",
   "metadata": {},
   "source": [
    "### Relation entre le nombre de jours entre la réservation et le vol et le prix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f270d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée des tranches (bins)\n",
    "original_df[\"days_bin\"] = pd.cut(original_df[\"days_left\"], bins=[0,5,10,20,40,60])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=original_df, x=\"days_bin\", y=\"price\")\n",
    "plt.title(\"Prix par tranche de days_left\")\n",
    "plt.xlabel(\"Tranche de jours avant le vol\")\n",
    "plt.ylabel(\"Prix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c5ca2",
   "metadata": {},
   "source": [
    "La moyenne des prix tend à diminuer avec le nombre de jours entre la réservation et le vol. Réserver plus tôt **semble** être associé à des prix plus bas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861b2815",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e08fc1",
   "metadata": {},
   "source": [
    "<a id=\"formuler-et-tester-des-hypotheses\"></a>\n",
    "\n",
    "# Formuler et tester des hypothèses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c732b5a",
   "metadata": {},
   "source": [
    "Après l'analyse technique, univariée et multivariée, on va maintenant formuler des **hypothèses statistiques** et les **tester**. L’idée est de partir de nos observations précédentes et de les transformer en hypothèses, que l’on va ensuite valider ou non à l’aide de tests statistiques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f960a0",
   "metadata": {},
   "source": [
    "On prendra pour ces tests un seuil de signification classique de 5% (α = 0.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d3b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b2119c",
   "metadata": {},
   "source": [
    "À partir des graphiques et des statistiques calculées précédemment, on retient les observations suivantes :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3596fdd8",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Durée du vol vs Prix\n",
    "\n",
    "**Question :** les vols plus longs sont-ils associés à des prix plus élevés ?\n",
    "\n",
    "On teste ici l’existence d’une **corrélation linéaire** entre :\n",
    "\n",
    "- `duration` (variable continue)\n",
    "- `price` (variable continue)\n",
    "\n",
    "**Hypothèses :**\n",
    "\n",
    "- $H_0$ : la corrélation linéaire entre `duration` et `price` est nulle.  \n",
    "- $H_1$ : la corrélation linéaire entre `duration` et `price` est non nulle.\n",
    "\n",
    "On utilise le **test de ...**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418384d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de corrélation entre duration et price\n",
    "corr_duration_price, p_value_duration_price = ...\n",
    "\n",
    "print(\"Corrélation (duration, price) :\", corr_duration_price)\n",
    "print(\"p-value :\", p_value_duration_price)\n",
    "\n",
    "if p_value_duration_price < alpha:\n",
    "    print(f\"→ p-value < {alpha} : on rejette H0.\")\n",
    "    print(\"Conclusion : il existe une corrélation linéaire significative entre la durée du vol et le prix.\")\n",
    "else:\n",
    "    print(f\"→ p-value ≥ {alpha} : on ne rejette pas H0.\")\n",
    "    print(\"Conclusion : on ne met pas en évidence de corrélation linéaire significative entre la durée du vol et le prix.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b5ce5",
   "metadata": {},
   "source": [
    "## 2. Compagnie aérienne vs Prix\n",
    "\n",
    "**Question :** les différentes compagnies pratiquent-elles en moyenne le même niveau de prix ?\n",
    "\n",
    "- Variable discrète : `airline` (plusieurs catégories)\n",
    "- Variable continue : `price`\n",
    "\n",
    "Pour garder des groupes suffisamment remplis, on limite l’étude aux **compagnies les plus fréquentes** dans le dataset.\n",
    "\n",
    "**Hypothèses :**\n",
    "\n",
    "- $H_0$ : le prix moyen des billets est le même pour toutes les compagnies considérées.  \n",
    "- $H_1$ : au moins une des compagnies a un prix moyen différent des autres.\n",
    "\n",
    "On utilise un **test **."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14a5fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On sélectionne les N compagnies les plus fréquentes\n",
    "N = 5\n",
    "top_airlines = original_df[\"airline\"].value_counts().nlargest(N).index\n",
    "df_top_airlines = original_df[original_df[\"airline\"].isin(top_airlines)]\n",
    "\n",
    "# Construction des groupes de prix par compagnie\n",
    "groups_price_by_airline = [\n",
    "    df_top_airlines[df_top_airlines[\"airline\"] == airline][\"price\"].values\n",
    "    for airline in top_airlines\n",
    "]\n",
    "\n",
    "# Test \n",
    "f_stat_airline, p_value_airline = ...\n",
    "\n",
    "print(\"Compagnies étudiées :\", list(top_airlines))\n",
    "print(\"Statistique F (airline vs price) :\", f_stat_airline)\n",
    "print(\"p-value :\", p_value_airline)\n",
    "\n",
    "if p_value_airline < alpha:\n",
    "    print(f\"→ p-value < {alpha} : on rejette H0.\")\n",
    "    print(\"Conclusion : le prix moyen n’est pas le même pour toutes ces compagnies (au moins une se distingue).\")\n",
    "else:\n",
    "    print(f\"→ p-value ≥ {alpha} : on ne rejette pas H0.\")\n",
    "    print(\"Conclusion : on n’a pas de preuve suffisante pour dire que le prix moyen diffère entre ces compagnies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f864043a",
   "metadata": {},
   "source": [
    "## 3. Nombre d’escales vs Prix\n",
    "\n",
    "**Question :** le prix moyen est-il identique quel que soit le nombre d’escales ?\n",
    "\n",
    "- Variable discrète : `stops`\n",
    "- Variable continue : `price`\n",
    "\n",
    "**Hypothèses :**\n",
    "\n",
    "- $H_0$ : le prix moyen des billets est le même pour tous les niveaux d’escales.  \n",
    "- $H_1$ : le prix moyen des billets dépend du nombre d’escales.\n",
    "\n",
    "On utilise un **test ...**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On s'assure que 'stops' est de type \"catégoriel\"/str pour bien définir les groupes et les ordonner\n",
    "stops_unique = sorted(original_df[\"stops\"].unique())\n",
    "print(\"Valeurs de 'stops' :\", stops_unique)\n",
    "\n",
    "groups_price_by_stops = [\n",
    "    original_df[original_df[\"stops\"] == s][\"price\"].values\n",
    "    for s in stops_unique\n",
    "]\n",
    "\n",
    "# Test \n",
    "f_stat_stops, p_value_stops = ...\n",
    "\n",
    "print(\"Statistique F (stops vs price) :\", f_stat_stops)\n",
    "print(\"p-value :\", p_value_stops)\n",
    "\n",
    "if p_value_stops < alpha:\n",
    "    print(f\"→ p-value < {alpha} : on rejette H0.\")\n",
    "    print(\"Conclusion : le prix moyen des billets dépend du nombre d’escales.\")\n",
    "else:\n",
    "    print(f\"→ p-value ≥ {alpha} : on ne rejette pas H0.\")\n",
    "    print(\"Conclusion : on n’a pas de preuve suffisante pour dire que le prix moyen varie selon le nombre d’escales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301df056",
   "metadata": {},
   "source": [
    "## 4. Nombre de jours avant le vol vs Prix\n",
    "\n",
    "**Question :** Réserver plus tôt est-il associé à des prix plus bas ?\n",
    "\n",
    "On étudie la relation entre :\n",
    "\n",
    "- `days_left` (nombre de jours entre la réservation et le vol)\n",
    "- `price` (prix du billet)\n",
    "\n",
    "**Hypothèses :**\n",
    "\n",
    "- $H_0$ : il n’existe pas de corrélation linéaire entre `days_left` et `price`.  \n",
    "- $H_1$ : il existe une corrélation linéaire entre `days_left` et `price` (par exemple, prix plus faible lorsque `days_left` augmente).\n",
    "\n",
    "On utilise le **test de ...**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119bbc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de\n",
    "corr_days_price, p_value_days_price = ...\n",
    "\n",
    "print(\"Corrélation (days_left, price) :\", corr_days_price)\n",
    "print(\"p-value :\", p_value_days_price)\n",
    "\n",
    "if p_value_days_price < alpha:\n",
    "    print(f\"→ p-value < {alpha} : on rejette H0.\")\n",
    "    print(\"Conclusion : il existe une corrélation linéaire significative entre le nombre de jours avant le vol et le prix.\")\n",
    "    print(\"Interprétation possible : réserver plus tôt est effectivement associé à des prix différents (souvent plus bas).\")\n",
    "else:\n",
    "    print(f\"→ p-value ≥ {alpha} : on ne rejette pas H0.\")\n",
    "    print(\"Conclusion : on ne met pas en évidence de corrélation linéaire significative entre days_left et price.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c03c5b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbce34",
   "metadata": {},
   "source": [
    "<a id=\"preprocessing\"></a>\n",
    "\n",
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e331867b",
   "metadata": {},
   "source": [
    "Après l'analyse technique, univariée, multivariée, puis les tests d’hypothèses, on va maintenant préparer les données pour la modélisation.\n",
    "\n",
    "L’objectif du preprocessing est de transformer notre dataset brut en un jeu de données exploitable par un modèle de machine learning :\n",
    "\n",
    "- Nettoyer les valeurs aberrantes\n",
    "- Encoder les variables catégorielles\n",
    "- Créer éventuellement quelques features supplémentaires\n",
    "- Normaliser les variables numériques\n",
    "- Préparer une pipeline scikit-learn réutilisable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa4bea",
   "metadata": {},
   "source": [
    "On part d'une copie du dataset initial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee205e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = original_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b8aa65",
   "metadata": {},
   "source": [
    "On commence par compter le nombre de valeurs manquantes par colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea5d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre de NaNs par colonne :\")\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75365785",
   "metadata": {},
   "source": [
    "## Encodage simple de `stops` et `class`\n",
    "\n",
    "Avant de construire la pipeline scikit-learn, on va encoder deux variables importantes :\n",
    "\n",
    "- `stops` : variable ordinale (zero, one, two_or_more) → 0 / 1 / 2\n",
    "- `class` : Economy / Business → 0 / 1\n",
    "\n",
    "Ces nouvelles colonnes numériques (`stops_num` et `class_num`) pourront ensuite être normalisées et utilisées comme de vraies variables numériques dans le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ec628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage ordinal de stops\n",
    "mapping_stops = ...\n",
    "df[\"stops_num\"] = ...\n",
    "print(df[[\"stops\", \"stops_num\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage binaire de class\n",
    "mapping_class = ...\n",
    "df[\"class_num\"] = ...\n",
    "print(df[[\"class\", \"class_num\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2130469f",
   "metadata": {},
   "source": [
    "## Séparation features / target et train/test split\n",
    "\n",
    "- **Target** : `price`\n",
    "- **Features** : toutes les autres colonnes utiles.\n",
    "\n",
    "On va :\n",
    "1. Supprimer la colonne `flight` (identifiant peu informatif pour le modèle).\n",
    "2. Supprimer les anciennes versions catégorielles de `stops` et `class` (on garde les versions numériques).\n",
    "3. Séparer en X (features) et y (target).\n",
    "4. Faire un `train_test_split` avec 20% des données en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab3826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enlève la colonne 'flight' (identifiant) et les anciennes versions de stops/class\n",
    "df_model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f16e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation features / target\n",
    "X = ...\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e35fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / test split\n",
    "X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe9e76a",
   "metadata": {},
   "source": [
    "## Définir les colonnes numériques et catégorielles (après le préprocessing simple)\n",
    "\n",
    "On sépare les features en deux groupes :\n",
    "\n",
    "- **Features numériques** : \n",
    "  - `duration`\n",
    "  - `days_left`\n",
    "  - `stops_num`\n",
    "  - `class_num`\n",
    "\n",
    "Ces variables seront imputées (si besoin) puis **standardisées** (mean=0, std=1).\n",
    "\n",
    "- **Features catégorielles** (nominales, sans ordre) :\n",
    "  - `airline`\n",
    "  - `source_city`\n",
    "  - `departure_time`\n",
    "  - `arrival_time`\n",
    "  - `destination_city`\n",
    "\n",
    "Ces variables seront **encodées en one-hot** via `OneHotEncoder` (avec `drop=\"first\"` pour éviter la multicolinéarité)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28957a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes numériques\n",
    "numeric_features = [\"duration\", \"days_left\", \"stops_num\", \"class_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3000e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes catégorielles\n",
    "categorical_features = [\"airline\", \"source_city\", \"departure_time\", \n",
    "                        \"arrival_time\", \"destination_city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89758c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline pour les variables numériques : ...\n",
    "numeric_transformer = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681be668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline pour les variables catégorielles : ...\n",
    "categorical_transformer = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c4e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer qui applique le bon traitement à chaque type de variable\n",
    "preprocessor = ...\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ce92f4",
   "metadata": {},
   "source": [
    "## Préprocesseur prêt pour la modélisation\n",
    "\n",
    "L’objet `preprocessor` contient désormais toute la logique de preprocessing :\n",
    "\n",
    "1. **Nettoyage** (via les imputers)\n",
    "2. **Encodage** des variables catégorielles (One-Hot)\n",
    "3. **Normalisation** des variables numériques (StandardScaler)\n",
    "\n",
    "Dans la partie suivante (*Modélisation*), on pourra facilement construire un modèle complet en créant une `Pipeline` :\n",
    "\n",
    "- étape 1 : `(\"preprocessor\", preprocessor)`\n",
    "- étape 2 : `(\"regressor\", <modèle_de_régression>)`\n",
    "\n",
    "Par exemple, une régression linéaire, une régression Ridge, un RandomForestRegressor, etc.\n",
    "\n",
    "Cette approche permet :\n",
    "- d’éviter les fuites de données (data leakage),\n",
    "- de réappliquer exactement les mêmes transformations sur les données de test,\n",
    "- et plus tard, sur de nouvelles données en production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86cc268",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df41a81e",
   "metadata": {},
   "source": [
    "<a id=\"Modelisation\"></a>\n",
    "\n",
    "# Modélisation\n",
    "\n",
    "Nous avons maintenant :\n",
    "\n",
    "- une cible : **`price`** (variable continue),\n",
    "- un jeu de features prétraitées (via l’objet `preprocessor`),\n",
    "- une séparation **train / test** : `X_train`, `X_test`, `y_train`, `y_test`.\n",
    "\n",
    "Nous sommes donc dans un cadre d’**apprentissage supervisé** pour un problème de **régression**.\n",
    "\n",
    "Dans cette section, nous allons :\n",
    "\n",
    "1. Construire une **baseline** avec un modèle naïf (DummyRegressor)\n",
    "2. Entraîner une **régression linéaire** (LinearRegression)\n",
    "3. Ajouter une **régression Ridge** (modèle linéaire régularisé)\n",
    "4. Tester un **modèle non linéaire** (RandomForestRegressor)\n",
    "5. Comparer les performances de tous ces modèles\n",
    "6. Illustrer le réglage d’**hyperparamètres** avec `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f86f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Petite fonction utilitaire pour évaluer un modèle\n",
    "def evaluate_model(\n",
    "    name,\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results_dict,\n",
    "    cv=5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Évalue un modèle avec validation croisée sur le train,\n",
    "    puis refit sur tout le train et évalue une fois sur le test.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    name : str\n",
    "        Nom du modèle (pour l'affichage et le dictionnaire de résultats).\n",
    "    model : estimator / Pipeline\n",
    "        Modèle ou Pipeline scikit-learn (déjà construit).\n",
    "    X_train, y_train : array-like\n",
    "        Données d'entraînement.\n",
    "    X_test, y_test : array-like\n",
    "        Données de test.\n",
    "    results_dict : dict\n",
    "        Dictionnaire dans lequel on stocke les résultats.\n",
    "    cv : int\n",
    "        Nombre de folds pour la validation croisée.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----- 1) Validation croisée sur le train -----\n",
    "    cv_results = cross_validate(\n",
    "        estimator=model,\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        cv=KFold(n_splits=cv, shuffle=True, random_state=42),\n",
    "        scoring={\n",
    "            \"mae\": \"neg_mean_absolute_error\",\n",
    "            \"rmse\": \"neg_root_mean_squared_error\",\n",
    "            \"r2\": \"r2\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Moyennes (on remet les signes positifs pour MAE / RMSE)\n",
    "    cv_mae_mean = -cv_results[\"test_mae\"].mean()\n",
    "    cv_mae_std  =  cv_results[\"test_mae\"].std()\n",
    "\n",
    "    cv_rmse_mean = -cv_results[\"test_rmse\"].mean()\n",
    "    cv_rmse_std  =  cv_results[\"test_rmse\"].std()\n",
    "\n",
    "    cv_r2_mean = cv_results[\"test_r2\"].mean()\n",
    "    cv_r2_std  = cv_results[\"test_r2\"].std()\n",
    "\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(f\"Validation croisée ({cv}-fold) sur le train :\")\n",
    "    print(f\"  MAE  (mean ± std) : {cv_mae_mean:.2f} ± {cv_mae_std:.2f}\")\n",
    "    print(f\"  RMSE (mean ± std) : {cv_rmse_mean:.2f} ± {cv_rmse_std:.2f}\")\n",
    "    print(f\"  R²   (mean ± std) : {cv_r2_mean:.4f} ± {cv_r2_std:.4f}\")\n",
    "\n",
    "    # ----- 2) Refit sur tout le train -----\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ----- 3) Évaluation finale sur le test -----\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_rmse = root_mean_squared_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    print(\"Évaluation finale sur le test :\")\n",
    "    print(f\"  Test MAE  : {test_mae:.2f}\")\n",
    "    print(f\"  Test RMSE : {test_rmse:.2f}\")\n",
    "    print(f\"  Test R²   : {test_r2:.4f}\")\n",
    "    print()\n",
    "\n",
    "    results_dict[name] = {\n",
    "        \"cv_mae_mean\": cv_mae_mean,\n",
    "        \"cv_mae_std\": cv_mae_std,\n",
    "        \"cv_rmse_mean\": cv_rmse_mean,\n",
    "        \"cv_rmse_std\": cv_rmse_std,\n",
    "        \"cv_r2_mean\": cv_r2_mean,\n",
    "        \"cv_r2_std\": cv_r2_std,\n",
    "        \"test_mae\": test_mae,\n",
    "        \"test_rmse\": test_rmse,\n",
    "        \"test_r2\": test_r2,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d47acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire pour stocker les résultats de tous les modèles\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aff5dd5",
   "metadata": {},
   "source": [
    "## 1. Baseline  DummyRegressor\n",
    "\n",
    "Avant d’entraîner de “vrais” modèles de Machine Learning, on commence par une **baseline naïve**.\n",
    "\n",
    "On utilise ici un `DummyRegressor` qui prédit toujours la **moyenne** des prix observés sur le jeu d’entraînement.\n",
    "\n",
    "Ce modèle :\n",
    "- ne regarde pas les features,\n",
    "- sert uniquement de **référence** : un bon modèle doit faire mieux que lui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc5bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = ...\n",
    "\n",
    "evaluate_model(\n",
    "    name=\"DummyRegressor (mean)\",\n",
    "    model=dummy_model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    results_dict=results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6a1c86",
   "metadata": {},
   "source": [
    "## 2. Régression linéaire  `LinearRegression`\n",
    "\n",
    "On passe maintenant à un premier “vrai” modèle de Machine Learning : la **régression linéaire**.\n",
    "\n",
    "Pour l’utiliser proprement avec nos données :\n",
    "\n",
    "- On intègre le **preprocessing** (encodage + normalisation) dans une `Pipeline`.\n",
    "- On ajoute ensuite un estimateur `LinearRegression`.\n",
    "\n",
    "La `Pipeline` permet de :\n",
    "\n",
    "- `fit` le préprocesseur uniquement sur le **train**,\n",
    "- appliquer exactement les mêmes transformations sur le **test**,\n",
    "- éviter les fuites de données (data leakage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc115b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_pipeline = ...\n",
    "\n",
    "evaluate_model(\n",
    "    name=\"LinearRegression\",\n",
    "    model=linreg_pipeline,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    results_dict=results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c84bbd",
   "metadata": {},
   "source": [
    "## 3. Régression linéaire régularisée  `Ridge`\n",
    "\n",
    "La régression linéaire classique peut parfois :\n",
    "\n",
    "- mal généraliser,\n",
    "- être sensible aux colinéarités entre features.\n",
    "\n",
    "La **régression Ridge** ajoute une **pénalité L2** sur la taille des coefficients, contrôlée par un hyperparamètre `alpha` :\n",
    "\n",
    "- `alpha` petit → peu de régularisation (proche de LinearRegression)\n",
    "- `alpha` grand → coefficients plus “petits”, modèle plus régularisé\n",
    "\n",
    "On va commencer par tester quelques valeurs de `alpha` “à la main”, sans GridSearch, pour voir l’impact sur les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907dbcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = ...\n",
    "\n",
    "for a in alphas:\n",
    "    ridge_pipeline = ...\n",
    "    \n",
    "    evaluate_model(\n",
    "        name=f\"Ridge (alpha={a})\",\n",
    "        model=ridge_pipeline,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        results_dict=results,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc7ddf",
   "metadata": {},
   "source": [
    "## 4. Modèle non linéaire  `RandomForestRegressor`\n",
    "\n",
    "Pour capturer des relations **non linéaires** entre les variables et le prix, on peut utiliser une **forêt aléatoire de régression** (`RandomForestRegressor`).\n",
    "\n",
    "Principe :\n",
    "\n",
    "- on entraîne plusieurs **arbres de décision** sur des sous-échantillons des données,\n",
    "- on moyenne leurs prédictions,\n",
    "- le modèle est souvent robuste et performant sur des données tabulaires.\n",
    "\n",
    "Hyperparamètres importants :\n",
    "\n",
    "- `n_estimators` : nombre d’arbres,\n",
    "- `max_depth` : profondeur maximale des arbres,\n",
    "- `min_samples_leaf` : nombre minimum d’échantillons dans une feuille.\n",
    "\n",
    "On commence avec des valeurs “raisonnables” et les hyperparamètres par défaut pour les autres. \n",
    "\n",
    "Temps d’entraînement plus long, mais souvent de bonnes performances (environ 5 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = ...\n",
    "\n",
    "evaluate_model(\n",
    "    name=\"RandomForestRegressor\",\n",
    "    model=rf_pipeline,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    results_dict=results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db019d61",
   "metadata": {},
   "source": [
    "## 5. Comparaison des modèles\n",
    "\n",
    "On regroupe maintenant les résultats de tous les modèles testés dans un tableau récapitulatif.\n",
    "\n",
    "On compare en particulier :\n",
    "\n",
    "- la **baseline** (DummyRegressor),\n",
    "- la **régression linéaire**,\n",
    "- la **régression Ridge** pour différentes valeurs de `alpha`,\n",
    "- la **Random Forest**.\n",
    "\n",
    "Les métriques regardées :\n",
    "\n",
    "- MAE (Mean Absolute Error)\n",
    "- RMSE (Root Mean Squared Error)\n",
    "- R² (coefficient de détermination)\n",
    "\n",
    "L’objectif est de voir :\n",
    "\n",
    "- quels modèles généralisent le mieux (bon score sur le test),\n",
    "- s’il y a de l’overfitting (écart train/test important),\n",
    "- et lequel on retiendrait comme modèle “principal” pour ce projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aa59b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).T\n",
    "\n",
    "results_df = ...\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f121d53",
   "metadata": {},
   "source": [
    "Ici, le meilleur modèle est clairement le **RandomForestRegressor**, qui capture bien les relations non linéaires et les interactions entre variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00f233b",
   "metadata": {},
   "source": [
    "On passe maintenant à l'entrainement du modèle final sur l'ensemble des données d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42,\n",
    "    ))\n",
    "])\n",
    "\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d94e9a5",
   "metadata": {},
   "source": [
    "<a id=\"evaluation-finale-du-modele\"></a>\n",
    "\n",
    "# Évaluation finale du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e2be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "mae = ...\n",
    "rmse = ...\n",
    "r2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b7de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test MAE  : {mae:.2f}\")\n",
    "print(f\"Test RMSE : {rmse:.2f}\")\n",
    "print(f\"Test R²   : {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d624c20",
   "metadata": {},
   "source": [
    "On obtient les performances finales du modèle sur le jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce77201",
   "metadata": {},
   "source": [
    "## Intervalle de confiance sur la MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b2abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Prédictions\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Erreurs absolues (une par observation)\n",
    "abs_errors = np.abs(y_test.to_numpy() - y_test_pred)\n",
    "\n",
    "# MAE = moyenne des erreurs absolues\n",
    "mae = abs_errors.mean()\n",
    "\n",
    "# Écart-type (std) des erreurs absolues\n",
    "sigma = abs_errors.std(ddof=1)  # ddof=1 -> écart-type \"échantillon\"\n",
    "\n",
    "# Erreur standard (SE)\n",
    "n = len(abs_errors)\n",
    "se = ...\n",
    "\n",
    "# z-score (95% = 1.96)\n",
    "z = 1.96\n",
    "\n",
    "# Intervalle de confiance\n",
    "ci_low = ...\n",
    "ci_high = ...\n",
    "\n",
    "print(f\"n = {n}\")\n",
    "print(f\"MAE = {mae:.2f}\")\n",
    "print(f\"std(|erreur|) = {sigma:.2f}\")\n",
    "print(f\"SE = {se:.4f}\")\n",
    "print(f\"IC 95% : [{ci_low:.2f}, {ci_high:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc974fda",
   "metadata": {},
   "source": [
    "Sur l’échantillon de test, la MAE vaut $1086.89$ INR. En construisant un intervalle de confiance à 95% suivant la formule : $$[\\text{MAE}-z\\cdot\\text{SE}; \\text{MAE}+z\\cdot\\text{SE}]$$\n",
    "\n",
    "On obtient $$[1066.24 ; 1107.55]$$\n",
    "\n",
    "Cela indique que, compte tenu de la taille finie du test, l’erreur moyenne “vraie” attendue en généralisation devrait se situer dans cette fourchette, avec une incertitude d’environ ±20.7 INR autour de la MAE observée.\n",
    "\n",
    "L’objectif est atteint : la MAE estimée est d’environ 10€, et l’intervalle de confiance à 95% reste entièrement sous le seuil de 15 €. \n",
    "En euros on a : $$[10.07 ; 10.46]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8774b63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c823b64c",
   "metadata": {},
   "source": [
    "# Export du modèle final avec le préprocesseur intégré dans une pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b791948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# best_model est déjà une Pipeline scikit-learn : (\"preprocessor\" -> ColumnTransformer) + (\"model\" -> RandomForestRegressor)\n",
    "# et il est déjà fit sur X_train, y_train\n",
    "\n",
    "ARTIFACT_DIR = Path(\"artifacts\")\n",
    "ARTIFACT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "MODEL_PATH = ARTIFACT_DIR / \"flight_price_model.joblib\"\n",
    "META_PATH  = ARTIFACT_DIR / \"flight_price_model.meta.json\"\n",
    "\n",
    "joblib.dump(best_model, MODEL_PATH)\n",
    "\n",
    "metadata = {\n",
    "    \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"artifact\": str(MODEL_PATH),\n",
    "    \"target\": \"price\",\n",
    "    \"expected_features\": [\n",
    "        \"airline\", \"source_city\", \"departure_time\", \"arrival_time\", \"destination_city\",\n",
    "        \"duration\", \"days_left\", \"stops_num\", \"class_num\"\n",
    "    ],\n",
    "    \"notes\": \"Pipeline scikit-learn (preprocessor + model). Utiliser .predict() directement.\"\n",
    "}\n",
    "META_PATH.write_text(json.dumps(metadata, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Modèle exporté :\", MODEL_PATH)\n",
    "print(\"Métadonnées :\", META_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projets (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
